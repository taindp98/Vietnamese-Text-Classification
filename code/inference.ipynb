{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from flask import Flask, request,render_template,jsonify\n",
    "from flask_cors import CORS\n",
    "import torch.nn as nn\n",
    "import flask\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def tokenize(text):\n",
    "    list_token = ViTokenizer.tokenize(text)\n",
    "    return list_token.split(' ')\n",
    "\n",
    "def encode_sentence(text, vocab2index, N=75):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "#     print(len(enc1))\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "#     print(len(encoded))\n",
    "    encoded_array = torch.from_numpy(encoded.astype(np.float32))\n",
    "    encoded_array = torch.reshape(encoded_array,(1,N))\n",
    "    \n",
    "    ## padding\n",
    "    pad_enc = torch.zeros([29,N])\n",
    "    encoded_array_pad = torch.cat([encoded_array,pad_enc])\n",
    "    return encoded_array_pad.long()\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/predict',methods=['POST'])\n",
    "def predict():\n",
    "    # text=request.get_data(as_text=True)\n",
    "    input_data = request.get_json(force=True)\n",
    "    text = input_data['message']\n",
    "    enc_vector = encode_sentence(text,vocab2index,22)\n",
    "    preds = load_model(enc_vector)\n",
    "    prop_preds = nn.functional.softmax(preds,dim=1)\n",
    "    pred_label = prop_preds.argmax().item()\n",
    "    label = ['type_edu','case','career']\n",
    "    # return label[pred_label]\n",
    "    return jsonify({\"intent\": label[pred_label]})\n",
    "model_path = '../model'\n",
    "load_model = load_checkpoint(os.path.join(model_path,'checkpoint_0.40826831261316937.pth'))\n",
    "vocab2index = torch.load(os.path.join(model_path,'vocab_12jul.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [12/Jul/2021 13:26:38] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Jul/2021 13:27:13] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    port=int(os.environ.get('PORT',5000))\n",
    "    app.run(port=port,debug=True,use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
